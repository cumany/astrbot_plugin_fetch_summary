import asyncio
import json
import re
from typing import Any, Dict, List, Optional
from urllib.parse import urlparse

import aiohttp

from astrbot.api import AstrBotConfig, logger
from astrbot.api.event import AstrMessageEvent, filter
from astrbot.api.event.filter import EventMessageType
from astrbot.api.star import Context, Star, register
import astrbot.api.message_components as Comp

DEFAULT_LLM_PROMPT = (
    "è¯·å°†ä»¥ä¸‹æ‘˜è¦æ¶¦è‰²æˆè‡ªç„¶çš„ä¸­æ–‡ç¾¤èŠç”¨è¯­ï¼Œä¿æŒåŸæ„ï¼š\n\n{summary}"
)

@register(
    "fetch_url_summarizer",
    "Cuman",
    "è‡ªåŠ¨è·å– URL å†…å®¹æ‘˜è¦çš„æ’ä»¶",
    "1.0.0",
    "https://github.com/cumany/astrbot_plugin_fetch_url_summarizer",
)
class URLSummarizerPlugin(Star):
    """URL æ‘˜è¦æ’ä»¶ä¸»ç±»ã€‚"""

    def __init__(self, context: Context, config: AstrBotConfig):
        super().__init__(context)
        self.config = config

        # å•æ¡æ¶ˆæ¯ä¸­å¯èƒ½å­˜åœ¨å¤šä¸ª URLï¼Œå› æ­¤é¢„å…ˆæ„å»ºæ­£åˆ™è¡¨è¾¾å¼å¤ç”¨ã€‚
        self.url_pattern = re.compile(
            r'''
            (?<![A-Za-z0-9._~%!$&'*+,;=:@/?#-])   # å·¦è¾¹ç•Œï¼ˆä¸å«æ‹¬å·ï¼‰
            https?://
            (?:[A-Za-z0-9-]+\.)+[A-Za-z0-9-]+     # åŸŸå
            (?::\d{2,5})?                         # ç«¯å£
            (?:/[^\s<>"\]]*)?                     # è·¯å¾„/æŸ¥è¯¢/ç‰‡æ®µï¼ˆæ’é™¤ ] é˜² Markdownï¼‰
            (?![A-Za-z0-9._~%!$&'*+,;=:@/?#-])    # å³è¾¹ç•Œï¼ˆä¸å«æ‹¬å·ï¼‰
            ''',
            re.IGNORECASE | re.VERBOSE,
        )

        # è‡ªå®šä¹‰æ‘˜è¦æç¤ºè¯ï¼ŒåŒºåˆ†ä¸åŒæœºå™¨äººçš„å›å¤ã€‚
        self.summary_prefix = self.config.get("summary_prefix", "ğŸ“å†…å®¹æ‘˜è¦ï¼š")

        logger.info("fetch_url_summarizer å·²åˆå§‹åŒ–")

    @filter.event_message_type(EventMessageType.GROUP_MESSAGE)
    async def on_message(self, event: AstrMessageEvent):
        """ç›‘å¬æ‰€æœ‰ç¾¤èŠæ¶ˆæ¯ï¼Œè‡ªåŠ¨å¤„ç†å…¶ä¸­çš„ URLã€‚"""
        try:
            # ---------- 1. è·³è¿‡æœºå™¨äººè‡ªèº«æ¶ˆæ¯ ----------
            if event.get_sender_id() == event.get_self_id():
                logger.debug("æ”¶åˆ°è‡ªèº«æ¶ˆæ¯ï¼Œå¿½ç•¥")
                return

            # ---------- 2. è·³è¿‡è½¬å‘/å¼•ç”¨ ----------
            for comp in event.message_obj.message:
                if isinstance(comp, (Comp.Forward, Comp.Reply)):
                    return

            # ---------- 3. æ‘˜è¦å¼€å…³ ----------
            if not self.config.get("enable_summary", True):
                logger.debug("æ‘˜è¦åŠŸèƒ½å·²å…³é—­ï¼Œè·³è¿‡å¤„ç†")
                return

            # ---------- 4. é»‘åå•ç¾¤ç»„ ----------
            group_id = event.get_group_id()
            if group_id:
                blacklist_keywords = self.config.get("blacklist_groups", [])
                # åªè¦ group_id ä¸­å‘½ä¸­ä»»æ„å…³é”®å­—å°±è·³è¿‡
                if any(kw in group_id for kw in blacklist_keywords):
                    logger.debug("ç¾¤ç»„ ID å‘½ä¸­é»‘åå•å…³é”®å­—ï¼Œè·³è¿‡å¤„ç†: %s", group_id)
                    return

            # ---------- 5. ç©ºæ¶ˆæ¯ / å…³é”®è¯è¿‡æ»¤ ----------
            message_text = event.message_str or ""
            if not message_text:
                return

            if self._is_summary_message(message_text):
                logger.debug("æ¶ˆæ¯å·²åŒ…å«å†…å®¹æ‘˜è¦ï¼Œé¿å…å¾ªç¯è§£æ")
                return
            trigger_keywords = self.config.get("trigger_keywords", [])
            if trigger_keywords and not any(k in message_text for k in trigger_keywords):
                logger.debug("æ¶ˆæ¯æœªåŒ…å«è§¦å‘å…³é”®è¯ï¼Œè·³è¿‡å¤„ç†")
                return

            # ---------- 6. æå–å¹¶è¿‡æ»¤ URL ----------
            urls = self._extract_urls(message_text)
            if not urls:
                return
            logger.info("æ£€æµ‹åˆ° %s ä¸ªURL: %s", len(urls), urls)

            blacklist_keywords = self.config.get("blacklist_keywords", [])

            def is_blacklisted(url: str) -> bool:
                return any(k in url for k in blacklist_keywords)

            for url in urls:
                if is_blacklisted(url):
                    logger.debug("URLå‘½ä¸­é»‘åå•å…³é”®è¯ï¼Œè·³è¿‡: %s", url)
                    continue
                try:
                    summary = await self._get_url_summary(url)
                    if summary:
                        parts = [url, summary]
                        if self.summary_prefix:
                            parts.insert(0, self.summary_prefix)
                        yield event.plain_result("\n".join(parts))
                except Exception as exc:
                    logger.error("å¤„ç†URL %s å¼‚å¸¸: %s", url, exc, exc_info=True)

        except Exception as exc:
            logger.error("on_message é¡¶å±‚å¼‚å¸¸: %s", exc, exc_info=True)


    def _is_summary_message(self, text: str) -> bool:
        """æ ¹æ®æ‘˜è¦å‰ç¼€åˆ¤æ–­æ˜¯å¦ä¸ºå·²å¤„ç†çš„æ‘˜è¦æ¶ˆæ¯ã€‚"""
        prefixes = [self.summary_prefix, "ğŸ“å†…å®¹æ‘˜è¦ï¼š", "å†…å®¹æ‘˜è¦ï¼š"]
        return any(prefix and prefix in text for prefix in prefixes)

    def _extract_urls(self, text: str) -> List[str]:
        match = self.url_pattern.search(text)
        if not match:
            return []

        url = match.group(0).rstrip('.,;:!?ï¼Œã€‚ï¼ï¼Ÿï¼šï¼›ã€)]ã€‘ã€‹â€™â€\'"')  # å»å°¾éƒ¨æ ‡ç‚¹

        for left, right in (('(', ')'), ('ï¼ˆ', 'ï¼‰')):
            lack = url.count(right) - url.count(left)
            if lack > 0:
                url = url[:-lack]

        url = url.lstrip('<([ï¼ˆã€ã€Š')  # å»æ‰å¸¸è§å·¦åŒ…è£¹ç¬¦
        return [url] if self._is_valid_url(url) else []

    def _is_valid_url(self, url: str) -> bool:
        """é€šè¿‡æ ‡å‡†åº“è§£æç»“æœåˆ¤æ–­ URL æ˜¯å¦æœ‰æ•ˆã€‚"""
        try:
            result = urlparse(url)
            return bool(result.scheme and result.netloc)
        except Exception:  # noqa: BLE001 - urlparse ç†è®ºä¸ŠåªæŠ› ValueError
            return False

    async def _postprocess_with_llm(self, summary: str) -> str:
        """å¯é€‰åœ°è°ƒç”¨å¤§æ¨¡å‹ï¼Œæ ¹æ®æç¤ºè¯å¯¹æ‘˜è¦è¿›è¡Œæ¶¦è‰²æˆ–ç¿»è¯‘ã€‚"""
        if not self.config.get("enable_llm_postprocess", False):
            return summary

        provider_id = self.config.get("provider", "")
        provider = (
            self.context.get_provider_by_id(provider_id)
            if provider_id
            else self.context.get_using_provider()
        )
        if not provider:
            logger.warning("æœªæ‰¾åˆ°å¯ç”¨çš„å¤§æ¨¡å‹æä¾›å•†ï¼Œè·³è¿‡ LLM å¤„ç†")
            return summary

        prompt_template = self.config.get("llm_prompt_template") or DEFAULT_LLM_PROMPT
        try:
            prompt = prompt_template.replace("{summary}", summary)
            if "{summary}" not in prompt_template:
                prompt = f"{prompt_template}\n\n{summary}"

            response = await provider.text_chat(
                prompt=prompt,
                session_id=None,
                contexts=[],
                image_urls=[],
                system_prompt="ä½ æ˜¯ä¸€ä½å–„äºæ¶¦è‰²æ–‡æœ¬çš„åŠ©æ‰‹ï¼Œä¿æŒå†…å®¹å®Œæ•´å‡†ç¡®ã€‚",
            )
            if response and getattr(response, "completion_text", None):
                return response.completion_text.strip() or summary
            logger.warning("å¤§æ¨¡å‹æœªè¿”å›æ–‡æœ¬å†…å®¹ï¼Œä¿ç•™åŸå§‹æ‘˜è¦")
            return summary
        except Exception as exc:  # noqa: BLE001 - æ•è·å¤§æ¨¡å‹è°ƒç”¨å¼‚å¸¸
            logger.error("å¤§æ¨¡å‹å¤„ç†æ‘˜è¦å¤±è´¥: %s", exc, exc_info=True)
            return summary


    async def _get_url_summary(self, url: str) -> Optional[str]:
        """è°ƒç”¨ä¸Šæ¸¸æ‘˜è¦æœåŠ¡è·å– URL æ‘˜è¦ã€‚"""
        timeout = self.config.get("timeout", 30)
        max_retries = self.config.get("max_retries", 2)

        for attempt in range(max_retries):
            try:
                logger.info("æ­£åœ¨è·å– URL æ‘˜è¦ (å°è¯• %s/%s): %s", attempt + 1, max_retries, url)
                content = await self._fetch_summary_from_service(url, timeout)
                if not content:
                    logger.warning("æ‘˜è¦æ¥å£è¿”å›äº†ç©ºå†…å®¹: %s", url)
                    return None

                content = await self._postprocess_with_llm(content)
                return content
            except asyncio.TimeoutError:
                logger.error("æ‘˜è¦æ¥å£è¯·æ±‚è¶…æ—¶: %s", url)
            except Exception as exc:  # noqa: BLE001 - è®°å½•åé‡è¯•
                logger.error("æ‘˜è¦æ¥å£è¯·æ±‚å¼‚å¸¸: %s", exc, exc_info=True)

            if attempt < max_retries - 1:
                await asyncio.sleep(2**attempt)

        logger.error("è·å– URL æ‘˜è¦å¤±è´¥ï¼Œå·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°: %s", url)
        return None

    async def _fetch_summary_from_service(self, url: str, timeout: int) -> Optional[str]:
        """ç›´æ¥è°ƒç”¨ articlesummarizer.com ä¸Šæ¸¸æ¥å£è·å–æ‘˜è¦ã€‚"""
        headers = {
            "accept": "*/*",
            "accept-language": "zh-CN,zh;q=0.9,en;q=0.8",
            "content-type": "application/json",
            "origin": "https://articlesummarizer.com",
            "referer": "https://articlesummarizer.com/",
            "user-agent": (
                "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                "AppleWebKit/537.36 (KHTML, like Gecko) Chrome/141.0.0.0 Safari/537.36"
            ),
        }
        payload: Dict[str, Any] = {"link": url, "website": "article-summarizer"}
        api_url = "https://pjfuothbq9.execute-api.us-east-1.amazonaws.com/upload-link"

        async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=timeout)) as session:
            async with session.post(api_url, headers=headers, json=payload) as response:
                if response.status != 200:
                    error_text = await response.text()
                    raise ValueError(f"æ‘˜è¦æ¥å£è¿”å›é 200 çŠ¶æ€ ({response.status}): {error_text}")

                raw_body = await response.text()
                try:
                    outer_data = json.loads(raw_body)
                except json.JSONDecodeError as exc:
                    raise ValueError("ä¸Šæ¸¸å“åº”ä¸æ˜¯æœ‰æ•ˆçš„ JSON") from exc

                body_text = outer_data.get("result", {}).get("body")
                if not body_text or not isinstance(body_text, str):
                    raise ValueError("ä¸Šæ¸¸å“åº”ç¼ºå°‘ `result.body` å­—æ®µæˆ–ç±»å‹é”™è¯¯")

                inner_data = json.loads(body_text)
                summary_text = inner_data.get("summary")
                if not summary_text or not isinstance(summary_text, str):
                    raise ValueError("è§£æåçš„æ‘˜è¦å†…å®¹ä¸ºç©ºæˆ–ç±»å‹é”™è¯¯")

                return summary_text.strip()

    async def terminate(self):
        """æ’ä»¶å¸è½½æ—¶æ‰§è¡Œæ¸…ç†é€»è¾‘ã€‚"""
        logger.info("fetch_url_summarizer æ’ä»¶å·²å¸è½½")


